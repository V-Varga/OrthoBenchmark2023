# -*- coding: utf-8 -*-
#!/bin/python
"""

Title: og_clust_counts.py
Date: 2023.11.07
Author: Vi Varga

Description:
	This program calculates counts for cluster membership for each program &
		percent identity threshold used in the OrthoBenchmark workflow. The input
		file is expected to be the output file from the create_ortho_db.py
		program. 

List of functions:
	No functions are used in this script.

List of standard and non-standard modules used:
	sys
	datetime.datetime
	pandas

Procedure:
	1. Importing modules & assigning command-line arguments. 
	2. Importing input database into Pandas dataframe. 
	3. Calculating counts of protein cluster sizes. 
	4. Creating clean dataframe with only counts & writing out results to tab-separated 
		text files.

Known bugs and limitations:
	- There is no quality-checking integrated into the code.
	- The output file name is not user-defined. 
	- This program is designed only to accept an input file created by the 
		create_ortho_db.py script. 

Usage:
	./og_clust_counts.py input_db
	OR
	python og_clust_counts.py input_db
	
	Where input_db must be a larger protein cluster assignment database generated by
		the create_ortho_db.py program. 

This script was written for Python 3.9.18, in Spyder 5.4.3. 

"""

# Part 1: Import necessary modules & assign command-line arguments

# import necessary modules
import sys # allows execution of script from command line
from datetime import datetime # access data from system regarding date & time
import pandas as pd # allows manipulation of dataframes in Python


# assign command line arguments
input_db = sys.argv[1]
#input_db = "../ProgramResults/Orthology_Comparison_DB__26-10-2023--174514.txt"

# designate automatic output file names
# first determine date & time of query
now = datetime.now()
time_now = now.strftime("%d-%m-%Y--%H%M%S")
#and create the resulting outfile name
output_db = "Ortho_Comparison_Counts__" + time_now + ".txt"
output_db_clean = "Ortho_Comparison_CountsClean__" + time_now + ".txt"


# Part 2: Import input database into Pandas dataframe

# import data into pandas dataframe
input_df = pd.read_csv(input_db, sep='\t', header=0, low_memory=False)


# Part 3: Calculate counts

for column in input_df: 
	# loop over the columns in the dataframe
	# ref: https://www.geeksforgeeks.org/loop-or-iterate-over-all-or-certain-columns-of-a-dataframe-in-python-pandas/
	if not column == "Query": 
		# skip over the first column with the query prot names
		# get the basename of the column
		# ref: https://note.nkmk.me/en/python-str-remove-strip/
		col_basename = column.replace('_parsed_pivot', '')
		count_col_name = col_basename + "_counts"
		# get counts of all columns & save results to a temporary dataframe
		# ref: https://www.geeksforgeeks.org/how-to-count-occurrences-of-specific-value-in-pandas-column/
		# ref: https://stackoverflow.com/questions/47136436/python-pandas-convert-value-counts-output-to-dataframe
		tmp_counts = input_df[column].value_counts(ascending=False).rename_axis(column).reset_index(name=count_col_name)
		# now add the new dataframe to the larger counts dataframe
		if 'counts_df' in globals():
			# first check if the dataframe already exists
			# if so, add the temporary counts dataframe onto the larger dataframe
			# join the contents of the input dataframe into the larger dataframe
			# ref: https://stackoverflow.com/questions/60341348/merge-multiple-dataframes-without-common-columns
			counts_df = pd.concat([counts_df, tmp_counts], axis=1)
		else: 
			# if the counts dataframe does not already exist
			# create it from the temporary counts dataframe
			counts_df = tmp_counts.copy()


# Part 4: Clean up dataframe & write out results

# Create cleaned up dataframe without cluster IDs
# ref: https://stackoverflow.com/questions/19071199/drop-columns-whose-name-contains-a-specific-string-from-pandas-dataframe
clean_counts_df = counts_df[counts_df.columns.drop(list(counts_df.filter(regex = '_parsed_pivot')))]


# write out results to tab-separated text files
counts_df.to_csv(output_db, index=False, header=True, sep = '\t')
clean_counts_df.to_csv(output_db_clean, index=False, header=True, sep = '\t')
